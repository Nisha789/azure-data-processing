{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "metadata": {},
      "source": [
        "from pyspark.sql.functions import sum,col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "metadata": {},
      "source": [
        "df = spark.read.load('abfss://synapse-datastore@adlsstgaccdemoneu.dfs.core.windows.net/raw-data/sales_data.csv',format='csv',header=True,inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Define the schema (database)\n",
        "spark.sql(\"CREATE DATABASE IF NOT EXISTS salesmart\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Perform some aggregation (eg. total_sales by year)\n",
        "aggregated_df = df.groupBy(\"YEAR_ID\").agg(sum(col(\"SALES\")).alias(\"Total_Sales\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "metadata": {},
      "source": [
        "aggregated_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable('salesmart.SalesAggregation')\n",
        "print(\"Write in Delta Completed !!!\")"
      ]
    }
  ]
}